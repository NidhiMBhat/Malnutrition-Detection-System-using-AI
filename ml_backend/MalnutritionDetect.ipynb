{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1146ba9e",
   "metadata": {},
   "source": [
    "# Malnutrition detection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ce43b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ac41e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "malnutrition = pd.read_csv('Malnutrition data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9305a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = malnutrition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a8e82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "malnutrition.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668337ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the number of entries and any missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae7817b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0946c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dealing with categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb22b74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Sex'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9728b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe714a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4ed429",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.hist(bins=50, figsize=(20,15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e7a48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualising informaiton about the Status column which is categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d96fcc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Status'].value_counts().plot(kind='bar', figsize=(10, 6), color='skyblue')\n",
    "\n",
    "plt.title('Distribution of Status')\n",
    "plt.xlabel('Status')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3262d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c87bd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b2d3eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9a9760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the unwanted columns as seen below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612be338",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('Low Income '.strip(), axis=1)\n",
    "df = df.drop('Lower Middle Income '.strip(), axis=1)\n",
    "df = df.drop('Upper Middle Income '.strip(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b42acb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e02e0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951f2a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating the labels and features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88d9685",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(\"Status\", axis=1)  # Features\n",
    "y = df[\"Status\"]  # Labels\n",
    "\n",
    "# X = df.iloc[:, :4]\n",
    "# y = df.iloc[:, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863f9c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualising the interger type data using a histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc5f97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.hist(bins=50, figsize=(20,15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613d97cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce372e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_plot = pd.concat([X, y], axis=1)\n",
    "\n",
    "# # Create a box plot\n",
    "# plt.figure(figsize=(12, 8))\n",
    "# sns.boxplot(data=df_plot, x='Status', y='Height') \n",
    "# plt.title('Box Plot of Age by Status')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0893863",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_plot = pd.concat([X, y], axis=1)\n",
    "\n",
    "# # Create box plots for all features\n",
    "# plt.figure(figsize=(16, 10))\n",
    "# sns.boxplot(data=df_plot.drop('Status', axis=1))\n",
    "# plt.title('Box Plots of Features by Status')\n",
    "# plt.xticks(rotation=45, ha='right')  # Rotate x-axis labels for better readability\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db61dfa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Splitting the dataset into training, validation and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dae8518",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d734e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Split the 'temp' sets into validation and test sets\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Print the shapes of the resulting sets\n",
    "print(\"Training set:\", X_train.shape, y_train.shape)\n",
    "print(\"Validation set:\", X_val.shape, y_val.shape)\n",
    "print(\"Testing set:\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be88a685",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# model = RandomForestClassifier(n_estimators=300)\n",
    "# model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9de2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict = model.predict(X_temp)\n",
    "# predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1f59bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "# print(confusion_matrix(y_temp, predict))\n",
    "# print(classification_report(y_temp, predict))\n",
    "# print(\"Accuracy Of Our Model Is:-\",accuracy_score(y_temp, predict)*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33a1b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf_classifier = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# # Train the classifier on the training set\n",
    "# rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# # Make predictions on the validation set\n",
    "# y_val_pred = rf_classifier.predict(X_val)\n",
    "\n",
    "# # Evaluate the accuracy on the validation set\n",
    "# val_accuracy = accuracy_score(y_val, y_val_pred)*100\n",
    "# print(f'Validation Accuracy: {val_accuracy:.2f}')\n",
    "\n",
    "# # Make predictions on the test set\n",
    "# y_test_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "# # Evaluate the accuracy on the test set\n",
    "# test_accuracy = accuracy_score(y_test, y_test_pred)*100\n",
    "# print(f'Test Accuracy: {test_accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c421a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "\n",
    "# Train the model on the training set\n",
    "model = RandomForestClassifier(n_estimators=300)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions on the validation set\n",
    "y_val_pred = model.predict(X_val)\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "print(\"Validation Set:\")\n",
    "print(confusion_matrix(y_val, y_val_pred))\n",
    "print(classification_report(y_val, y_val_pred))\n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy_score(y_val, y_val_pred) * 100))\n",
    "\n",
    "# Predictions on the temporary set\n",
    "y_temp_pred = model.predict(X_temp)\n",
    "\n",
    "# Evaluate the model on the temporary set\n",
    "print(\"\\nTemporary Set:\")\n",
    "print(confusion_matrix(y_temp, y_temp_pred))\n",
    "print(classification_report(y_temp, y_temp_pred))\n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy_score(y_temp, y_temp_pred) * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd0b526",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "\n",
    "# Train the model on the training set\n",
    "model = RandomForestClassifier(n_estimators=300)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions on the validation set\n",
    "y_val_pred = model.predict(X_val)\n",
    "\n",
    "# Print the predicted labels and compare with the actual labels\n",
    "print(\"Predicted Labels:\", y_val_pred)\n",
    "print(\"Actual Labels   :\", y_val.tolist())  # Convert y_val to a list for easy comparison\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "print(\"Validation Set:\")\n",
    "print(confusion_matrix(y_val, y_val_pred))\n",
    "print(classification_report(y_val, y_val_pred))\n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy_score(y_val, y_val_pred) * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb776a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "\n",
    "# Train the model on the training set\n",
    "model = RandomForestClassifier(n_estimators=300)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions on the test set\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "# Print the predicted labels and compare with the actual labels\n",
    "print(\"Predicted Labels (Test Set):\", y_test_pred)\n",
    "print(\"Actual Labels (Test Set)   :\", y_test.tolist())  # Convert y_test to a list for easy comparison\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "print(\"\\nTest Set:\")\n",
    "print(confusion_matrix(y_test, y_test_pred))\n",
    "print(classification_report(y_test, y_test_pred))\n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy_score(y_test, y_test_pred) * 100))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5e114a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming X contains your features and y contains your labels\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Split the 'temp' sets into validation and test sets\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Create an SVM model\n",
    "svm_model = SVC(kernel='linear', random_state=42)  # You can adjust the kernel and other parameters based on your data\n",
    "\n",
    "# Train the SVM model on the training set\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions on the validation set\n",
    "y_val_pred = svm_model.predict(X_val)\n",
    "\n",
    "# Evaluate the SVM model on the validation set\n",
    "print(\"Validation Set:\")\n",
    "print(confusion_matrix(y_val, y_val_pred))\n",
    "print(classification_report(y_val, y_val_pred))\n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy_score(y_val, y_val_pred) * 100))\n",
    "\n",
    "# Predictions on the test set\n",
    "y_test_pred = svm_model.predict(X_test)\n",
    "\n",
    "# Evaluate the SVM model on the test set\n",
    "print(\"\\nTest Set:\")\n",
    "print(confusion_matrix(y_test, y_test_pred))\n",
    "print(classification_report(y_test, y_test_pred))\n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy_score(y_test, y_test_pred) * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34de7550",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below, I used neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60489ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "\n",
    "# Load your dataset\n",
    "data = pd.read_csv('Malnutrition data.csv')\n",
    "\n",
    "# Encode categorical variable 'Sex' using one-hot encoding\n",
    "data = pd.get_dummies(data, columns=['Sex'], drop_first=True)\n",
    "\n",
    "# Convert 'Status' column to numerical values using label encoding\n",
    "label_encoder = LabelEncoder()\n",
    "data['Status'] = label_encoder.fit_transform(data['Status'])\n",
    "\n",
    "# Split the dataset into features (X) and target variable (y)\n",
    "X = data.drop('Status', axis=1)\n",
    "y = data['Status']\n",
    "\n",
    "# Split the data into training, validation, and test sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Build a simple neural network\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')  # Binary classification output\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the neural network on the training set\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_val, y_val))\n",
    "\n",
    "# Predictions on the validation set\n",
    "y_val_pred_prob = model.predict(X_val)\n",
    "y_val_pred = (y_val_pred_prob > 0.5).astype(int)\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "print(\"\\nValidation Set:\")\n",
    "print(confusion_matrix(y_val, y_val_pred))\n",
    "print(classification_report(y_val, y_val_pred))\n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy_score(y_val, y_val_pred) * 100))\n",
    "\n",
    "# Predictions on the test set\n",
    "y_test_pred_prob = model.predict(X_test)\n",
    "y_test_pred = (y_test_pred_prob > 0.5).astype(int)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "print(\"\\nTest Set:\")\n",
    "print(confusion_matrix(y_test, y_test_pred))\n",
    "print(classification_report(y_test, y_test_pred))\n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy_score(y_test, y_test_pred) * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8170ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5e86ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the code below, I encoded the non-numeric label to numeric and used the SVM algorithm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2919b85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Assuming X contains your features and y contains your labels\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Split the 'temp' sets into validation and test sets\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Encode non-numeric labels in y_train using LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "\n",
    "# Create an SVM model\n",
    "svm_model = SVC(kernel='linear', random_state=42)\n",
    "\n",
    "# Train the SVM model on the training set\n",
    "svm_model.fit(X_train, y_train_encoded)\n",
    "\n",
    "# Encode non-numeric labels in y_val and y_test\n",
    "y_val_encoded = label_encoder.transform(y_val)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "# Predictions on the validation set\n",
    "y_val_pred = svm_model.predict(X_val)\n",
    "\n",
    "# Evaluate the SVM model on the validation set\n",
    "print(\"Validation Set:\")\n",
    "print(confusion_matrix(y_val_encoded, y_val_pred))\n",
    "print(classification_report(y_val_encoded, y_val_pred))\n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy_score(y_val_encoded, y_val_pred) * 100))\n",
    "\n",
    "# Predictions on the test set\n",
    "y_test_pred = svm_model.predict(X_test)\n",
    "\n",
    "# Evaluate the SVM model on the test set\n",
    "print(\"\\nTest Set:\")\n",
    "print(confusion_matrix(y_test_encoded, y_test_pred))\n",
    "print(classification_report(y_test_encoded, y_test_pred))\n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy_score(y_test_encoded, y_test_pred) * 100))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b4d70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below, I encoded the non numeric labels to numeric and used Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9967e738",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Assuming 'status' is the column to be encoded in your dataset\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "y_val_encoded = label_encoder.transform(y_val)  # Assuming you have a validation set 'y_val'\n",
    "\n",
    "# Train the model on the training set\n",
    "model = RandomForestClassifier(n_estimators=300)\n",
    "model.fit(X_train, y_train_encoded)\n",
    "\n",
    "# Predictions on the test set\n",
    "y_test_pred_encoded = model.predict(X_test)\n",
    "y_val_pred_encoded = model.predict(X_val)  # Assuming you have a validation set 'X_val'\n",
    "\n",
    "# Decode the predicted labels back to original status labels\n",
    "y_test_pred = label_encoder.inverse_transform(y_test_pred_encoded)\n",
    "y_val_pred = label_encoder.inverse_transform(y_val_pred_encoded)\n",
    "\n",
    "# Print the predicted labels and compare with the actual labels for both test and validation sets\n",
    "print(\"Test Set:\")\n",
    "print(\"Predicted Labels (Test Set):\", y_test_pred)\n",
    "print(\"Actual Labels (Test Set)   :\", y_test.tolist())  # Convert y_test to a list for easy comparison\n",
    "print(\"\\nValidation Set:\")\n",
    "print(\"Predicted Labels (Validation Set):\", y_val_pred)\n",
    "print(\"Actual Labels (Validation Set)   :\", y_val.tolist())  # Convert y_val to a list for easy comparison\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "print(\"\\nTest Set:\")\n",
    "print(confusion_matrix(y_test, y_test_pred))\n",
    "print(classification_report(y_test, y_test_pred))\n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy_score(y_test, y_test_pred) * 100))\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "print(\"\\nValidation Set:\")\n",
    "print(confusion_matrix(y_val, y_val_pred))\n",
    "print(classification_report(y_val, y_val_pred))\n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy_score(y_val, y_val_pred) * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a0da73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0ff8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Checking the matching of the numeric values and there corresponding actual label values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b4e086",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Assuming 'status' is the column to be encoded in your dataset\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Create a sample DataFrame with your data\n",
    "# Replace this with your actual dataset\n",
    "data = {'status': ['Stunting', 'Overweight', 'Underweight', 'Wasting', 'Stunting']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Fit and transform the LabelEncoder on the original label column\n",
    "encoded_labels = label_encoder.fit_transform(df['status'])\n",
    "\n",
    "# Print the mapping between encoded values and original labels\n",
    "print(\"Encoded Labels:\")\n",
    "for label, encoded_value in zip(label_encoder.classes_, range(len(label_encoder.classes_))):\n",
    "    print(f\"Encoded Value: {encoded_value} -> Original Label: {label}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0e1335",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Trying out SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2dfb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install -U imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95875634",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Split the dataset into training, validation, and test sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Split the 'temp' sets into validation and test sets\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Print the shapes of the resulting sets\n",
    "print(\"Before SMOTE - Training set:\", X_train.shape, y_train.shape)\n",
    "print(\"Validation set:\", X_val.shape, y_val.shape)\n",
    "print(\"Testing set:\", X_test.shape, y_test.shape)\n",
    "\n",
    "# Check the number of samples in the minority class\n",
    "min_class_samples = min(y_train.value_counts())\n",
    "\n",
    "# Apply SMOTE only to the training set with k_neighbors\n",
    "k_neighbors = min(6, min_class_samples - 1)  # Ensure k_neighbors is less than min_class_samples\n",
    "smote = SMOTE(random_state=42, k_neighbors=k_neighbors)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Print the shapes of the resampled training set\n",
    "print(\"\\nAfter SMOTE - Resampled Training set:\", X_train_resampled.shape, y_train_resampled.shape)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b33d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the distribution of the target variable before and after SMOTE\n",
    "print(\"Before SMOTE - Training set:\")\n",
    "print(y_train.value_counts())\n",
    "\n",
    "# Print the distribution of the target variable after SMOTE\n",
    "print(\"\\nAfter SMOTE - Resampled Training set:\")\n",
    "print(y_train_resampled.value_counts())\n",
    "\n",
    "# Print the distribution of the target variable in the validation set\n",
    "print(\"\\nValidation set:\")\n",
    "print(y_val.value_counts())\n",
    "\n",
    "# Print the distribution of the target variable in the testing set\n",
    "print(\"\\nTesting set:\")\n",
    "print(y_test.value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6102d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the dataset into training, validation, and test sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Split the 'temp' sets into validation and test sets\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Print the shapes of the resulting sets\n",
    "print(\"Before SMOTE - Training set:\", X_train.shape, y_train.shape)\n",
    "print(\"Validation set:\", X_val.shape, y_val.shape)\n",
    "print(\"Testing set:\", X_test.shape, y_test.shape)\n",
    "\n",
    "# Check the number of samples in the minority class\n",
    "min_class_samples = min(y_train.value_counts())\n",
    "\n",
    "# Apply SMOTE only to the training set with k_neighbors\n",
    "k_neighbors = min(6, min_class_samples - 1)  # Ensure k_neighbors is less than min_class_samples\n",
    "smote = SMOTE(random_state=42, k_neighbors=k_neighbors)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Remove unwanted features from all sets\n",
    "columns_to_remove = [\"Low Income\", \"Lower Middle Income\", \"Upper Middle Income\"]\n",
    "X_train_resampled = X_train_resampled.drop(columns=columns_to_remove, axis=1)\n",
    "X_val = X_val.drop(columns=columns_to_remove, axis=1)\n",
    "X_test = X_test.drop(columns=columns_to_remove, axis=1)\n",
    "\n",
    "# Print the shapes of the resampled training set\n",
    "print(\"\\nAfter SMOTE - Resampled Training set:\", X_train_resampled.shape, y_train_resampled.shape)\n",
    "\n",
    "# Continue with your modeling and evaluation steps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335c7c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of columns to be removed\n",
    "columns_to_remove = [\"Low Income\", \"Lower Middle Income\", \"Upper Middle Income\"]\n",
    "\n",
    "# Remove the specified columns from the DataFrame\n",
    "X_train_resampled_filtered = X_train_resampled.drop(columns=columns_to_remove, axis=1)\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(X_train_resampled_filtered.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbb0c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first few rows of the modified feature DataFrame\n",
    "print(\"Features after removing columns:\")\n",
    "print(X_train_resampled_filtered.head())\n",
    "\n",
    "# Display the column names of the modified feature DataFrame\n",
    "print(\"\\nFeature column names after removing columns:\")\n",
    "print(X_train_resampled_filtered.columns)\n",
    "\n",
    "# Display the target variable (labels) in the modified training set\n",
    "print(\"\\nLabels in the modified training set:\")\n",
    "print(y_train_resampled.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff4ae0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185c346c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8c5808",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb832497",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_resampled_encoded = label_encoder.fit_transform(y_train_resampled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b009ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b3db80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing unwanted features from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42497d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # Assuming your original dataset is df\n",
    "# # List of columns to be removed\n",
    "# columns_to_remove = [\"Low Income\", \"Lower Middle Income\", \"Upper Middle Income\"]\n",
    "\n",
    "# # Create a new DataFrame with the specified columns removed\n",
    "# df_filtered = df.drop(columns=columns_to_remove, axis=1)\n",
    "\n",
    "# # Display the resulting DataFrame\n",
    "# print(df_filtered.head())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b9408b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Assuming 'status' is the column to be encoded in your dataset\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_resampled_encoded = label_encoder.fit_transform(y_train_resampled)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "y_val_encoded = label_encoder.transform(y_val)  # Assuming you have a validation set 'y_val'\n",
    "\n",
    "# Train the model on the resampled training set\n",
    "model = RandomForestClassifier(n_estimators=300)\n",
    "model.fit(X_train_resampled_filtered, y_train_resampled_encoded)  # Using the filtered feature set\n",
    "\n",
    "# Predictions on the test set\n",
    "y_test_pred_encoded = model.predict(X_test)\n",
    "y_val_pred_encoded = model.predict(X_val)  # Assuming you have a validation set 'X_val'\n",
    "\n",
    "# Decode the predicted labels back to original status labels\n",
    "y_test_pred = label_encoder.inverse_transform(y_test_pred_encoded)\n",
    "y_val_pred = label_encoder.inverse_transform(y_val_pred_encoded)\n",
    "\n",
    "# Print the predicted labels and compare with the actual labels for both test and validation sets\n",
    "print(\"Test Set:\")\n",
    "print(\"Predicted Labels (Test Set):\", y_test_pred)\n",
    "print(\"Actual Labels (Test Set)   :\", y_test.tolist())  # Convert y_test to a list for easy comparison\n",
    "print(\"\\nValidation Set:\")\n",
    "print(\"Predicted Labels (Validation Set):\", y_val_pred)\n",
    "print(\"Actual Labels (Validation Set)   :\", y_val.tolist())  # Convert y_val to a list for easy comparison\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "print(\"\\nTest Set:\")\n",
    "print(confusion_matrix(y_test, y_test_pred))\n",
    "print(classification_report(y_test, y_test_pred))\n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy_score(y_test, y_test_pred) * 100))\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "print(\"\\nValidation Set:\")\n",
    "print(confusion_matrix(y_val, y_val_pred))\n",
    "print(classification_report(y_val, y_val_pred))\n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy_score(y_val, y_val_pred) * 100))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
